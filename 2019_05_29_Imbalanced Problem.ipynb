{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/cesurdagli/Desktop/Capstone Project/Feb17NoNull_Merged.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pass_fail1']=df['pass_fail'].map({'PASS':1, 'FAIL':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing empty values with null values\n",
    "df=df.replace(r'^\\s+$', np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>highestEd</th>\n",
       "      <th>reason</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   highestEd  reason  level\n",
       "0        2.0     2.0    2.0\n",
       "1        3.0     2.0    2.0\n",
       "2        3.0     2.0    2.0\n",
       "3        4.0     2.0    1.0\n",
       "4        2.0     2.0    2.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recoding the categorical values\n",
    "clean_nums = {'highestEd': {'DD':5, 'MD':4, 'BD':3, 'HS':2, 'AD':1, 'OT':0},\n",
    "                  'reason': {'review':4, 'learn':3, 'assignment':2, 'curious':1, 'other':0},\n",
    "                  'level': {'confident':2, 'some':1, 'little':0},\n",
    "             'testLevel': {'GR':1, 'UG':0}}\n",
    "df.replace(clean_nums, inplace=True)\n",
    "df[['highestEd', 'reason', 'level']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the null values\n",
    "df=df[df['reason'].notnull() & df['highestEd'].notnull() & df['level'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9579, 54)\n",
      "0    7400\n",
      "1    2179\n",
      "Name: pass_fail1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.pass_fail1.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  <class 'pandas.core.frame.DataFrame'> (9579, 29)\n",
      "y:  <class 'pandas.core.series.Series'> (9579,)\n",
      "df.pass_fail shape:  (9579,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Define the features\n",
    "X=df[['testLevel', 'highestEd', 'reason','level', 'quality_Satisfaction1', 'authenticProblems1',\n",
    "       'demonstration1', 'application1', 'activation1', 'ALT2', 'ALT3',\n",
    "       'quality_Satisfaction2', 'demonstration2', 'demonstration3', 'ALT4',\n",
    "       'authenticProblems2', 'integration1', 'activation2',\n",
    "       'authenticProblems3', 'integration2', 'application3', 'integration3',\n",
    "       'activation3', 'application4', 'demonstration5',\n",
    "       'ALT1Reversed', 'demonstration4Reversed',\n",
    "       'quality_Satisfaction3Reversed', 'quality_Satisfaction4Reversed']]\n",
    "print(\"X: \", type(X), X.shape)\n",
    "\n",
    "# Define the target\n",
    "y = df.pass_fail1\n",
    "print(\"y: \", type(y), y.shape)\n",
    "print(\"df.pass_fail shape: \", df.pass_fail1.shape)\n",
    "\n",
    "# Split the data into a training and test set.\n",
    "Xlr, Xtestlr, ylr, ytestlr = train_test_split(X, y, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'> (7184, 29) 7184\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'> (2395, 29) 2395\n",
      "\n",
      "\n",
      "<class 'pandas.core.series.Series'> (7184,) 7184\n",
      "\n",
      "\n",
      "<class 'pandas.core.series.Series'> (2395,) 2395\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\")\n",
    "print(type(Xlr), Xlr.shape, len(Xlr)) #TrainX\n",
    "\n",
    "print(\"\\n\")\n",
    "print(type(Xtestlr), Xtestlr.shape, len(Xtestlr)) #TestX\n",
    "\n",
    "print(\"\\n\")\n",
    "print(type(ylr), ylr.shape, len(ylr)) #Trainy\n",
    "\n",
    "print(\"\\n\")\n",
    "print(type(ytestlr), ytestlr.shape, len(ytestlr)) #Testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Test] Accuracy score (y_predict_test, ytestlr): 0.7803757828810021\n",
      "\n",
      "\n",
      "[Training] Accuracy score: (ylr, y_predict_training) 0.7700445434298441\n",
      "Accuracy: 0.7803757828810021\n",
      "Precision: 0.5151515151515151\n",
      "Recall: 0.027239709443099273\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1852   16]\n",
      " [ 510   17]]\n",
      "\n",
      "[Test Classification Report:]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.99      0.88      1868\n",
      "           1       0.52      0.03      0.06       527\n",
      "\n",
      "    accuracy                           0.78      2395\n",
      "   macro avg       0.65      0.51      0.47      2395\n",
      "weighted avg       0.72      0.78      0.70      2395\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cesurdagli/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "\n",
    "# Construct the LogisticRegression model\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# Fit the model on the training data.\n",
    "clf.fit(Xlr, ylr) \n",
    "\n",
    "# Print the accuracy from the testing data.\n",
    "\n",
    "y_predict_test = clf.predict(Xtestlr)\n",
    "print(\"\\n\")\n",
    "print(\"[Test] Accuracy score (y_predict_test, ytestlr):\",accuracy_score(y_predict_test, ytestlr))\n",
    "\n",
    "\n",
    "# Printout the training score\n",
    "y_predict_training = clf.predict(Xlr)\n",
    "print(\"\\n\")\n",
    "print(\"[Training] Accuracy score: (ylr, y_predict_training)\",accuracy_score(ylr, y_predict_training))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_predict_test, ytestlr))\n",
    "print(\"Precision:\",metrics.precision_score(ytestlr, y_predict_test))\n",
    "print(\"Recall:\",metrics.recall_score(ylr, y_predict_training))\n",
    "print(\"\\n\")\n",
    "print('Confusion Matrix:')\n",
    "\n",
    "cnf_matrix = metrics.confusion_matrix(ytestlr, y_predict_test)\n",
    "print(cnf_matrix)\n",
    "print('')\n",
    "print(\"[Test Classification Report:]\")\n",
    "print(classification_report(ytestlr, y_predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling techniques — Undersample majority class\n",
    "using from imblearn.under_sampling import RandomUnderSampler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({0: 1652, 1: 1652})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "rus = RandomUnderSampler(random_state=5)\n",
    "X_rus, y_rus = rus.fit_resample(Xlr, ylr)\n",
    "print('Resampled dataset shape %s' % Counter(y_rus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cesurdagli/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5883089770354906\n",
      "Precision: 0.296\n",
      "Recall: 0.6318785578747628\n",
      "F1 Score: 0.40314769975786924\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1076  792]\n",
      " [ 194  333]]\n",
      "\n",
      "\n",
      "[Test Classification Report:]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.58      0.69      1868\n",
      "           1       0.30      0.63      0.40       527\n",
      "\n",
      "    accuracy                           0.59      2395\n",
      "   macro avg       0.57      0.60      0.54      2395\n",
      "weighted avg       0.73      0.59      0.62      2395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "downsampled = LogisticRegression().fit(X_rus, y_rus)\n",
    "downsampled_pred = downsampled.predict(Xtestlr)    \n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(ytestlr, downsampled_pred))\n",
    "print(\"Precision:\",metrics.precision_score(ytestlr, downsampled_pred))\n",
    "print(\"Recall:\",metrics.recall_score(ytestlr, downsampled_pred))\n",
    "print(\"F1 Score:\",metrics.f1_score(ytestlr, downsampled_pred))\n",
    "print(\"\\n\")\n",
    "print('Confusion Matrix:')\n",
    "cnf_matrix = metrics.confusion_matrix(ytestlr, downsampled_pred)\n",
    "print(cnf_matrix)\n",
    "print(\"\\n\")\n",
    "print(\"[Test Classification Report:]\")\n",
    "print(classification_report(ytestlr, downsampled_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling techniques — Oversample majority class\n",
    "using from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({1: 5532, 0: 5532})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=5)\n",
    "X_res, y_res = ros.fit_resample(Xlr, ylr)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cesurdagli/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6041753653444677\n",
      "Precision: 0.3056325023084026\n",
      "Recall: 0.6280834914611005\n",
      "F1 Score: 0.41118012422360245\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1116  752]\n",
      " [ 196  331]]\n",
      "\n",
      "\n",
      "[Test Classification Report:]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.60      0.70      1868\n",
      "           1       0.31      0.63      0.41       527\n",
      "\n",
      "    accuracy                           0.60      2395\n",
      "   macro avg       0.58      0.61      0.56      2395\n",
      "weighted avg       0.73      0.60      0.64      2395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "upsampled = LogisticRegression().fit(X_res, y_res)\n",
    "upsampled_pred = upsampled.predict(Xtestlr)    \n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(ytestlr, upsampled_pred))\n",
    "print(\"Precision:\",metrics.precision_score(ytestlr, upsampled_pred))\n",
    "print(\"Recall:\",metrics.recall_score(ytestlr, upsampled_pred))\n",
    "print(\"F1 Score:\",metrics.f1_score(ytestlr, upsampled_pred))\n",
    "print(\"\\n\")\n",
    "print('Confusion Matrix:')\n",
    "cnf_matrix = metrics.confusion_matrix(ytestlr, upsampled_pred)\n",
    "print(cnf_matrix)\n",
    "print(\"\\n\")\n",
    "print(\"[Test Classification Report:]\")\n",
    "print(classification_report(ytestlr, upsampled_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE Generate synthetic samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=5, ratio=1.0)\n",
    "SX_train, Sy_train = sm.fit_sample(Xlr, ylr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 5532, 0: 5532})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(Sy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cesurdagli/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5962421711899791\n",
      "Precision: 0.3010849909584087\n",
      "Recall: 0.6318785578747628\n",
      "F1 Score: 0.4078383343539498\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[1095  773]\n",
      " [ 194  333]]\n",
      "\n",
      "\n",
      "[Test Classification Report:]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.59      0.69      1868\n",
      "           1       0.30      0.63      0.41       527\n",
      "\n",
      "    accuracy                           0.60      2395\n",
      "   macro avg       0.58      0.61      0.55      2395\n",
      "weighted avg       0.73      0.60      0.63      2395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smote = LogisticRegression().fit(SX_train, Sy_train)\n",
    "\n",
    "smote_pred = smote.predict(Xtestlr)\n",
    "    \n",
    "print(\"Accuracy:\",metrics.accuracy_score(ytestlr, smote_pred))\n",
    "print(\"Precision:\",metrics.precision_score(ytestlr, smote_pred))\n",
    "print(\"Recall:\",metrics.recall_score(ytestlr, smote_pred))\n",
    "print(\"F1 Score:\",metrics.f1_score(ytestlr, smote_pred))\n",
    "print(\"\\n\")\n",
    "print(\"Confusion Matrix\")\n",
    "cnf_matrix = metrics.confusion_matrix(ytestlr, smote_pred)\n",
    "print(cnf_matrix)\n",
    "print(\"\\n\")\n",
    "print(\"[Test Classification Report:]\")\n",
    "print(classification_report(ytestlr, smote_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "sm = SMOTE(random_state=5, ratio=1.0)\n",
    "AX_train, Ay_train = sm.fit_sample(Xlr, ylr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5532, 5532])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(Ay_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5962421711899791\n",
      "Precision: 0.3010849909584087\n",
      "Recall: 0.6318785578747628\n",
      "F1 Score: 0.4078383343539498\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[1095  773]\n",
      " [ 194  333]]\n",
      "\n",
      "\n",
      "[Test Classification Report:]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.59      0.69      1868\n",
      "           1       0.30      0.63      0.41       527\n",
      "\n",
      "    accuracy                           0.60      2395\n",
      "   macro avg       0.58      0.61      0.55      2395\n",
      "weighted avg       0.73      0.60      0.63      2395\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cesurdagli/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "adasyn = LogisticRegression().fit(AX_train, Ay_train)\n",
    "\n",
    "adasyn_pred = adasyn.predict(Xtestlr)\n",
    "    \n",
    "print(\"Accuracy:\",metrics.accuracy_score(ytestlr, adasyn_pred))\n",
    "print(\"Precision:\",metrics.precision_score(ytestlr, adasyn_pred))\n",
    "print(\"Recall:\",metrics.recall_score(ytestlr, adasyn_pred))\n",
    "print(\"F1 Score:\",metrics.f1_score(ytestlr, adasyn_pred))\n",
    "print(\"\\n\")\n",
    "print(\"Confusion Matrix\")\n",
    "cnf_matrix = metrics.confusion_matrix(ytestlr, adasyn_pred)\n",
    "print(cnf_matrix)\n",
    "print(\"\\n\")\n",
    "print(\"[Test Classification Report:]\")\n",
    "print(classification_report(ytestlr, adasyn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7657620041753653\n",
      "Precision: 0.3068181818181818\n",
      "Recall: 0.051233396584440226\n",
      "F1 Score: 0.0878048780487805\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[1807   61]\n",
      " [ 500   27]]\n",
      "\n",
      "\n",
      "[Test Classification Report:]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.97      0.87      1868\n",
      "           1       0.31      0.05      0.09       527\n",
      "\n",
      "    accuracy                           0.77      2395\n",
      "   macro avg       0.55      0.51      0.48      2395\n",
      "weighted avg       0.68      0.77      0.69      2395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# train model\n",
    "rfc = RandomForestClassifier(n_estimators=300).fit(Xlr, ylr)\n",
    "\n",
    "# Predict on test set\n",
    "rfc_pred = rfc.predict(Xtestlr)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(ytestlr, rfc_pred))\n",
    "print(\"Precision:\",metrics.precision_score(ytestlr, rfc_pred))\n",
    "print(\"Recall:\",metrics.recall_score(ytestlr, rfc_pred))\n",
    "print(\"F1 Score:\",metrics.f1_score(ytestlr, rfc_pred))\n",
    "\n",
    "cnf_matrix = metrics.confusion_matrix(ytestlr, rfc_pred)\n",
    "print(\"\\n\")\n",
    "print(\"Confusion Matrix\")\n",
    "cnf_matrix = metrics.confusion_matrix(ytestlr, rfc_pred)\n",
    "print(cnf_matrix)\n",
    "print(\"\\n\")\n",
    "print(\"[Test Classification Report:]\")\n",
    "print(classification_report(ytestlr, rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
